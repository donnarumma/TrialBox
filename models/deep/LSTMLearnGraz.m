function   net = LSTMLearnGraz(data_trials,par)
% function net = LSTMLearnGraz(data_trials,par)
InField             = par.InField;
numEpochs           = par.numEpochs;
log_train           = par.log_train;
log_valid           = par.log_valid;
miniBatchSize       = par.miniBatchSize;
validationFrequency = par.validationFrequency;
% log_test            = par.log_test;
% numHiddenUnits      = par.numHiddenUnits;
verbose             = 1;

labels              = categorical([data_trials.trialType])';
numClasses          = length(unique(labels));

X3d                     = cat(3,data_trials.(InField));                     % nCells x nTimes x nTrials
% X3d         = permute(X3d,[3,1,2]);                             % nTrials x nCells x nTimes
% each row is a "synergy" -> [x_1(1), ... x_nChannels(1), x_1(2), ... x_nChannels(2), ... , x_1(nTimes), ... x_nChannels(nTimes),    

X4d                 = reshape(X3d,size(X3d,1),size(X3d,2),1,size(X3d,3)); % nTrials x nChannels x 1 x nTimes
[nCells, nTimes, nChannels, nTrials] = size(X4d);
X4d                 = permute(X4d,[3,2,1,4]);                             % nChannels x nTimes x nCells x nTrials

XTrain              = X4d(:,:,:,log_train);
TTrain              = labels(log_train);
XTrain              = squeeze(XTrain);
for iTr=1:length(log_train)
    % XTr{iTr}=XTrain(:,:,iTr);
    XTr{iTr}=XTrain(:,:,iTr)';
end
XTrain              = XTr;

XValid              = X4d(:,:,:,log_valid);
TValid              = labels(log_valid);
XValid              = squeeze(XValid);

for iVa=1:length(log_valid)
    % XVa{iVa}=XValid(:,:,iVa);
    XVa{iVa}=XValid(:,:,iVa)';
end
XValid              = XVa;

imageSize           = [nChannels, nTimes, nCells];

layers = [  imageInputLayer(imageSize,Normalization="none"), ... %projectAndReshapeLayer([nChannels,nCells,nTimes]), ...                                                ...                         
            convolution2dLayer(32,40,Padding="same",Stride=2,WeightL2Factor=2), ... %transposedConv2dLayer(1,nChannels,Cropping='same',Stride=2),   ...                   
            convolution2dLayer(32,40,Padding="same",Stride=2,WeightL2Factor=2), ... %transposedConv2dLayer(1,nChannels,Cropping='same',Stride=2),   ...                   
            batchNormalizationLayer('Epsilon',10^-5,'MeanDecay',0.1),                           ...                                                          ...
            functionLayer(@(X) X.^2), ...             
            averagePooling2dLayer([1,2],'Stride',[1,7]),                                            ...
            functionLayer(@(X) log(X)),                                                         ...                                                                          ...
            fullyConnectedLayer(numClasses),                                                    ...
            flattenLayer, ...
            dropoutLayer(0.5),                                                                  ...
            softmaxLayer,                                                                       ...
            classificationLayer];

layers = [  sequenceInputLayer(nCells),                 ... %projectAndReshapeLayer([nChannels,nCells,nTimes]), ...                                                ...                         
            convolution1dLayer(32,40,Padding="same",Stride=2,WeightL2Factor=2), ... %transposedConv2dLayer(1,nChannels,Cropping='same',Stride=2),   ...                   
            batchNormalizationLayer('Epsilon',10^-5,'MeanDecay',0.1),                           ...                                                          ...
            functionLayer(@(X) X.^2), ... averagePooling2dLayer([1,2],'Stride',[1,7]),                                            ...
            functionLayer(@(X) log(X)),                                                         ...                                                                          ...
            fullyConnectedLayer(numClasses),                                                    ...
            flattenLayer, ...
            dropoutLayer(0.5),                                                                  ...
            softmaxLayer,                                                                       ...
            classificationLayer];

layers = [ ...
    sequenceInputLayer(nCells)
    bilstmLayer(par.numLatentChannels,OutputMode="last")
    fullyConnectedLayer(numClasses)
    softmaxLayer
    classificationLayer];

if isempty (XValid)
    options = trainingOptions("adam", ...
    ExecutionEnvironment="cpu", ...
    GradientThreshold=1, ...
    MaxEpochs=numEpochs, ... 
    MiniBatchSize=miniBatchSize, ...
    SequenceLength="longest", ... Shuffle="never", ...
    Verbose=verbose, ... 
    Plots="training-progress");
else
    options = trainingOptions("adam", ...
        ExecutionEnvironment="cpu", ...
        GradientThreshold=1, ...
        MaxEpochs=numEpochs, ... 
        MiniBatchSize=miniBatchSize, ...
        SequenceLength="longest", ... Shuffle="never", ...
        Verbose=verbose, ... 
        Plots="training-progress", ...
        ValidationData={XValid,TValid}, ...
        ValidationFrequency=validationFrequency);
end
net                     = trainNetwork(XTrain,TTrain,layers,options);
