function   net = SCNLearn(data_trials,par)
% function net = SCNLearn(data_trials,par)
InField             = par.InField;
numEpochs           = par.numEpochs;
log_train           = par.log_train;
log_valid           = par.log_valid;
miniBatchSize       = par.miniBatchSize;
validationFrequency = par.validationFrequency;
% log_test            = par.log_test;
% numHiddenUnits      = par.numHiddenUnits;
verbose             = 1;

labels              = categorical([data_trials.trialType])';
numClasses          = length(unique(labels));

X3d                     = cat(3,data_trials.(InField));                     % nCells x nTimes x nTrials
% X3d         = permute(X3d,[3,1,2]);                             % nTrials x nCells x nTimes
% each row is a "synergy" -> [x_1(1), ... x_nChannels(1), x_1(2), ... x_nChannels(2), ... , x_1(nTimes), ... x_nChannels(nTimes),    

X4d                     = reshape(X3d,size(X3d,1),size(X3d,2),1,size(X3d,3)); % nTrials x nChannels x 1 x nTimes
[nCells, nTimes, nChannels, nTrials] = size(X4d);

XTrain              = X4d(:,:,:,log_train);
TTrain              = labels(log_train);

XValid              = X4d(:,:,:,log_valid);
TValid              = labels(log_valid);

imageSize           = [nCells, nTimes, nChannels];

layers = [  imageInputLayer(imageSize,Normalization="none"),                                    ...
            convolution2dLayer(par.kernsize,  par.numLatentChannels,Padding="same",Stride=2),   ...
            batchNormalizationLayer('Epsilon',10^-5,'MeanDecay',0.1),                           ...                                                          ...
            functionLayer(@(X) X.^2), ... %reluLayer,                                           ...
            averagePooling2dLayer(5,'Stride',[1,7]),                                            ...
            functionLayer(@(X) log(X)),                                                         ...                                                                          ...
            fullyConnectedLayer(numClasses),                                                    ...
            dropoutLayer(0.5),                                                                  ...
            softmaxLayer,                                                                       ...
            classificationLayer];

if isempty (XValid)
    options = trainingOptions("adam", ...
    ExecutionEnvironment="cpu", ...
    GradientThreshold=1, ...
    MaxEpochs=numEpochs, ... 
    MiniBatchSize=miniBatchSize, ...
    SequenceLength="longest", ... Shuffle="never", ...
    Verbose=verbose, ... 
    Plots="training-progress");
else
    options = trainingOptions("adam", ...
        ExecutionEnvironment="cpu", ...
        GradientThreshold=1, ...
        MaxEpochs=numEpochs, ... 
        MiniBatchSize=miniBatchSize, ...
        SequenceLength="longest", ... Shuffle="never", ...
        Verbose=verbose, ... 
        Plots="training-progress", ...
        ValidationData={XValid,TValid}, ...
        ValidationFrequency=validationFrequency);
end
net                     = trainNetwork(XTrain,TTrain,layers,options);
